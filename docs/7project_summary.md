# 小组综合报告

## 项目概述

本次P2P网贷违约预测项目以借款合同LC主数据、还款明细LP和投资者快照LCIS为核心数据来源，面向合同级“是否会逾期”的风险识别场景。数据侧，LC共328,553条合同记录、LP共3,203,276条期次记录、LCIS共292,539条投资快照；在统一观察截面（2017-02-22）下，结合贷款理论到期日和还款轨迹，最终圈定76,725条有效合同样本，其中国内正常样本43,817条（约57.1%），违约样本32,908条（约42.9%），形成轻度不平衡数据集。

标签构建采用“LP聚合+LCIS补充”的二元逻辑：对已到期合同，若LP聚合后的 `sum_DPD>0` 则记为违约（标签=1），反之为未违约（标签=0）；对尚未到理论到期但LCIS最新 `标当前状态=逾期中` 的合同，补充为违约样本。整个过程在 `outputs/middata/LC_labeled_samples.csv` 中留痕，未到期样本则输出到 `LC_invalid_samples.csv` 备查。模型层面，项目以ROC-AUC≥0.70及成本敏感指标（FN:FP=2:1）为总体目标，在保持可复现性的前提下，搭建了一条涵盖数据准备、特征工程、模型训练与阈值调优的自动化流水线。

项目组共四名成员，分工如下：

- 项目经理周燕：负责需求梳理、排期与内外部协调，统筹风险与交付。
- 数据科学家张一凡：主导数据理解、质量评估、清洗规则设计与数据资产落地。
- 机器学习算法工程师王琰元：负责特征工程实现、模型训练、阈值调优与结果解释。

整个项目由 `python3 -m ai_homework.cli.run_pipeline` 这一统一入口驱动，内部拆分为数据准备和模型训练两大子流水线：`prepare_data` 负责读取 `data/raw/source_data/` 中的三张原始表，完成清洗、标签构建、特征生成与数据集拆分；`model_training` 直接消费 `data/processed/{train,valid,test}.parquet`，完成多模型训练与评估。每次运行都会在 `outputs/logs` 输出完整日志，并在 `outputs/reports`、`outputs/artifacts` 中生成指标表、阈值搜索轨迹和SHAP图等工件。最终，在成本权重从FN:FP=5:1调整为2:1后，CatBoost模型在Precision与expected cost上表现最优，LightGBM和XGBoost在高召回方面提供补充。

## 项目经理工作报告

### 与客户沟通及需求澄清

项目初期与客户召开了两轮需求澄清会：第一轮集中在行业背景和业务目标上，明确本项目是为了支撑P2P平台贷前审批和贷后预警，核心问题是“合同在整个周期内是否发生过逾期”；第二轮聚焦在数据可用性与验收标准上，确认标签生成逻辑必须可审计、可复现。基于LP统一 `recorddate=2017-02-22` 的现实约束，双方约定仅以理论到期日早于该截面的合同作为有效观察样本，对未到期合同统一剔除并输出单独文件，避免标签污染。

在指标侧，客户起初希望采用“FN:FP=5:1”的保守策略，把漏判坏客户的成本定义得更高；随着第一次完整流水线运行和成本试算完成后，发现该策略会导致召回率接近1但Precision约0.43，误拒大量好客户。经过多轮沟通和对 `model_metrics.csv` 的联合分析，最终将成本设定调整为FN:FP=2:1，转而以“控制坏账风险的前提下，明显降低误拒率”为新目标。本次报告中的所有指标均围绕这一新成本策略展开。

### 进度与里程碑

项目按照“需求分析 → 数据理解与方案设计 → 数据准备流水线实现 → 模型训练与调参 → 测试与复盘 → 报告与交付”六个阶段推进。数据准备部分在11月16日凌晨完成完整跑通，产出 `LC_cleaned.csv`、`LC_labeled_samples.csv`、`loan_master.parquet` 以及拆分后的 `train/valid/test.parquet`。同日中午完成基于FN:FP=5:1的模型训练和阈值搜索，下午在保持数据与超参不变的前提下，通过 `python3 -m ai_homework.cli.run_pipeline --skip-data` 快速完成FN:FP=2:1策略下的复跑，对比不同成本配置下的Precision/Recall与expected cost差异。

项目进展依赖日志与中间产物进行量化跟踪：每个阶段结束后，项目经理会核对 `outputs/logs/*.log` 中的关键统计（样本量、特征数、AUC等），并在团队内部记录当前run_identifier，确保后续所有分析和图表都能准确回溯到对应运行。

### 团队协作

项目实施过程中，团队围绕配置和目录结构建立了统一规范：所有与数据清洗、特征工程、模型训练相关的参数集中在 `configs/data_processing.yaml` 与 `configs/model_training.yaml` 中维护，源代码遵循 `src/ai_homework/` 的模块化布局，运行产物严格落盘到 `outputs/` 与 `data/interim/`、`data/processed/`。数据科学家与算法工程师共同确定特征白名单与泄露黑名单，并在 `src/ai_homework/features/constants.py` 中集中维护；任何特征调整都通过配置文件控制，而非直接改动代码，方便版本管理。

测试工程师根据《模型训练结果摘要》中的路径约定，设计了针对 `model_metrics.csv`、各类图表以及阈值搜索记录的检查清单。每次流水线跑完后，团队通过短会快速复盘：由数据科学家汇报本轮样本质量与特征变化，算法工程师说明模型指标与阈值变化，测试工程师反馈是否存在异常波动。项目经理则负责对外同步阶段性成果，并将重要决策（如成本权重调整、特征消融方案）整理进文档，形成可传阅的项目记录。

### 成果评估

最终交付内容包括：清洗后的数据集ZIP包（含有效样本与无效样本分层）、特征矩阵及拆分数据集、四类模型及其权重文件、阈值搜索历史与调参记录、模型指标总表与图形报告，以及本次小组综合报告。根据最新一轮FN:FP=2:1配置的结果，CatBoost在测试集上实现Precision 0.532、Recall 0.747、ROC-AUC约0.686，对应expected cost约为5.74k；LightGBM在Recall端略有优势（0.816），expected cost也控制在5.74k附近。相比FN:FP=5:1策略下约6.5k的expected cost，新策略在降低误拒的同时整体业务成本明显下降。

从项目管理角度看，数据质量风险通过前置的异常统计与一致性校验得到了有效缓释；模型过拟合风险通过基线模型和消融实验进行对照；进度风险则通过脚本化与日志化手段进行控制，最终项目在既定时间窗口内完成各阶段交付。

## 数据科学家工作报告

### 原始数据质量评估

P2P_PPDAI_DATA中的LC、LP、LCIS三类原始表在数据类型、缺失情况和一致性上差异较大：LC以数值与分类型字段为主，存在年龄小于18岁或大于70岁的越界值，金额字段在高分位出现长尾；LP包含约320万条还款期次记录，`recorddate` 固定为2017-02-22，`还款日期` 缺失率约48.7%，缺失部分与“尚未还款”含义高度重合；LCIS则包含37个字段，既有金额也有状态与认证信息，`标当前状态` 的原始枚举不完全规范，部分字段存在空字符串和非法取值。

在样本圈定环节，经对LC与LP联合计算，发现约255,529笔合同在观察截面时仍未到理论到期日，占总量约78%，若直接参与建模会严重扭曲违约率估计，因此被统一标记为未到期样本并剔除。剩余样本再叠加LCIS“逾期中”快照后形成76,725条有效合同，为后续建模提供基础。

### 数据清洗策略与不可用数据分析

数据清洗分为三个层次：字段级清洗、样本级筛选和标签层补充。字段层面，数值字段采用双侧截尾和中位数填补，对金额和期限类变量按P99进行Winsorize，对年龄字段进行区间裁剪；分类字段统一映射到标准枚举，将非标准取值归类为 `Unknown`，并在必要时新增缺失指示列，方便后续建模使用。样本层面，通过对LP聚合计算 `sum_DPD`、最大期数与理论到期日，识别并剔除未到期合同，同时在 `outputs/middata/principal_inconsistencies.csv` 和 `term_inconsistencies.csv` 中记录“借款金额与应还本金不一致”、“借款期限与LP最大期数不一致”等异常。

标签层面，在有效合同基础上，数据科学家与算法工程师共同审定违约规则：`sum_DPD>0` 的合同直接标记为违约；对于LP信息不足但LCIS最新记录为“逾期中”的合同，通过 `label_source` 字段补充标签来源以便审计。综合上述处理，不可用数据主要集中在四类：一是仍在履约期的合同；二是关键字段缺失或取值非法的记录；三是金额和期数严重不一致的合同；四是状态字段使用了非标准枚举。成因分别来自单一观察截面带来的时间截断、系统缺乏强制校验、录入标准不统一以及业务流程调整未同步到数据字典。

### 数据采集与治理建议

结合本次数据质量评估，建议从源头到仓库建立一套闭环的数据治理机制：在源系统中对关键字段（如年龄、金额、期限、状态）设置值域和枚举校验，禁止非法取值入库；在数据入仓环节按批次生成质量报告，对缺失率、非法枚举、极端值比例等核心指标设定阈值预警；在ETL与特征构建过程中保留字段的来源和加工链路，便于后续审计和问题追踪。

在数据采集层面，可考虑：增加多截面LP快照，减少因单一 `recorddate` 带来的时间偏差；扩大LCIS对整体合同的覆盖率，并在字段中记录采集时间和场景；为重要行为字段补充采集日志记录（如设备信息、渠道来源），为后续时序建模和风险分析打基础。通过这些改进，可以在未来阶段进一步提升样本代表性和特征稳定性。

## 机器学习算法工程师工作报告

### 模型方案选择

模型层面，本项目围绕“可解释性 + 工业级性能”选择了四类代表性算法：逻辑回归、LightGBM、XGBoost和CatBoost。逻辑回归作为线性基线，用于校验特征方向与风险变量的总体关系，并为未来评分卡建设预留空间；LightGBM和XGBoost作为主流GBDT实现，在大规模稀疏特征场景下具备较好的训练效率和泛化表现；CatBoost对类别特征的原生支持较好，默认参数稳定，是工业界常见的生产候选。

选型过程中，团队不仅对比了AUC、F1等传统指标，还引入了expected cost这一成本敏感指标，将FN和FP的业务损失纳入统一框架。在FN:FP=5:1的初始策略下，四类模型均能在验证集上实现接近1的Recall和约0.60的F1，但Precision约0.43，expected cost集中在6.5k左右；在调整为FN:FP=2:1后，CatBoost的Precision提升至0.53左右，AUC保持在0.686，expected cost下降到约5.74k，综合表现最为平衡。

### 训练配置与超参调优

在数据拆分上，流水线采用两段式策略：优先尝试基于借款成功日期的时间切分，若出现集合为空等异常则自动退回到按标签分层的70%/15%/15%随机拆分。本次运行中最终采用了分层随机方案，保证训练、验证、测试集在标签分布上的一致性。训练时统一固定随机种子与交叉验证策略，以便多次运行间对比。

超参调优方面，各模型使用网格搜索或小范围试探相结合的方式：逻辑回归围绕正则强度 `C` 在{0.1,1,10,20}范围内搜索，最终选定 `C=0.1`、`class_weight=balanced`、`max_iter=500`；LightGBM在 `num_leaves∈{31,63,127}`、`min_child_samples∈{5,10,20,40}`、`min_split_gain∈{0.0,0.1}` 等参数上搜索，最终组合为 `num_leaves=127`、`max_depth=8`、`min_child_samples=40`，`scale_pos_weight` 根据样本不平衡度自动计算约为2.66；XGBoost则以 `max_depth=5`、`learning_rate=0.03`、`min_child_weight=5`、`gamma=0.1`、`subsample=0.6` 为最优组合；CatBoost固定 `iterations=400`、`learning_rate=0.05`、`class_weights=[1.0,4.0]`，在 `depth∈{5,7}` 与 `l2_leaf_reg∈{3,7}` 中选择了 `depth=7`、`l2_leaf_reg=3`。

在阈值调优层面，全部模型在训练完成后都会经历一次201点网格搜索，阈值范围为0.05~0.95。对于每个候选阈值，流水线计算 `objective_score = -(fn_cost * FN + fp_cost * FP) / N`，选择得分最高的一点作为 `best_threshold`，并连同FN、FP、Precision、Recall和expected cost一起写入 `summary_{model}.json`。在FN:FP=2:1配置下，最终阈值落在Logistic 0.41、LightGBM 0.536、XGBoost 0.545、CatBoost 0.6845这一组相对偏高的区间，体现出模型在新成本策略下更倾向于放行好客户。

### 数据预处理与特征工程实现

特征工程部分严格防止信息泄露，仅使用申请时即可获取的字段构造特征矩阵。流水线在 `build_feature_dataframe()` 中完成基础特征（如loan_amount、loan_term、interest_rate、rating_numeric）、客户画像与认证特征（如first_loan_flag、phone_verified）、历史行为特征（如history_repay_ratio、history_overdue_terms）以及交互与比例特征（如loan_term_history_overdue_rate、outstanding_to_history_amount_ratio、loan_amount_rating_interaction）的统一生成。数值列统一使用StandardScaler缩放，类别字段经One-Hot编码后与数值列拼接，确保输出矩阵可被所有候选模型复用。

为控制维度与冗余，流水线启用了投票式特征选择策略：通过皮尔逊相关系数筛掉高度共线的变量，结合卡方检验挑选与标签相关度高的离散特征，再利用随机森林重要性评估综合贡献度；最终保留约70个特征作为本轮训练的输入。特征消融实验表明，在移除 `loan_date_year_*` 等时间标签相关特征后，LightGBM的Precision略有提升而Recall略有下降，expected cost整体保持稳定，说明现有特征体系在信息与稳定性之间达成了较好的平衡。

### 模型表现摘要

在FN:FP=2:1策略下，四类模型在测试集上的综合表现如下：

- CatBoost：Accuracy 0.610、Precision 0.532、Recall 0.747、F1 0.621、ROC-AUC ≈0.686、expected cost ≈5.74k；
- LightGBM：Accuracy 0.580、Precision 0.506、Recall 0.816、F1 0.625、ROC-AUC ≈0.682、expected cost ≈5.74k；
- XGBoost：Accuracy 0.571、Precision 0.500、Recall 0.830、F1 0.624、ROC-AUC ≈0.685、expected cost ≈5.77k；
- Logistic Regression：Accuracy 0.579、Precision 0.506、Recall 0.786、F1 0.615、ROC-AUC ≈0.669、expected cost ≈5.91k。

从混淆矩阵来看，相较于5:1成本下几乎“全拦截”的策略，新阈值让四个模型左上角TN显著增加，CatBoost的TN从不足200条提升到约3,300条，意味着有大量本应通过的正常客户被成功自动放行；与此同时，右上角FP从约6,500条降至约3,200~3,900条，误拒数量明显下降。SHAP分析显示，`loan_term`、`history_repay_ratio`、`loan_term_history_overdue_rate` 和 `outstanding_to_history_amount_ratio` 等特征在三类树模型中均位居前列，说明“借款期限+历史还款行为+当前负债压力”是驱动模型判断违约风险的主线信号。

## 项目总结

### 行业延展需求

从本次案例可以看到，违约预测只是消费金融与小微贷风控体系中的一个核心环节。围绕同一套合同级风险评分，其他客户往往还会提出额度建议、利率差异化定价、复贷筛选、贷后预警等多层次需求。例如，在贷前阶段，可以将本模型输出的逾期概率映射为风险等级，用于自动化审批和授信额度上限控制；在贷中阶段，结合客户的用信和还款行为轨迹，对评分明显恶化的客户提前调整额度或利率；在贷后阶段，可以利用模型对存量客户进行分层，优先安排催收资源或提前干预高风险人群。

### 商业模式设想

基于当前技术方案，可以将产品设计为“风控评分服务+策略咨询”的组合：底层通过API提供实时评分与批量评分能力，对接客户的审批系统、贷后系统和数据中台；上层则围绕成本敏感阈值调优、策略模拟和A/B测试提供顾问服务。在收费模式上，可以结合基础订阅（覆盖一定调用量的评分服务）与按量计费（超出部分按笔计价），对需要额外支持的客户提供模型迁移、特征定制和监管报告编制等增值服务。

### 推广策略

在推广路径上，可以先在合作方内部选择一个业务线或客群进行试点，通过A/B测试对比“有模型/无模型”场景下的误拒率、坏账率和人工审核工作量变化，将收益量化呈现；同时，与外部合作机构搭建数据沙盒，采用脱敏历史数据进行回测演示，让潜在客户在低风险环境下充分理解模型效果。对监管关注程度较高的机构，则重点强调模型的可解释性（通过SHAP特征贡献、阈值决策曲线等）和全流程日志记录，降低技术落地的合规顾虑。

### 上线性能要求与迭代规划

结合本次实验结果，若要在生产环境中投入使用，建议将测试集ROC-AUC≥0.70、Precision≥0.50、Recall≥0.75作为最低性能门槛，并以expected cost作为核心业务指标长期监控。同时，需要建设配套的模型监控与运维机制：包括输入数据分布与缺失率监控、评分分布与阈值命中率监控、按月评估F1和expected cost的漂移情况，一旦核心指标偏离基线5%以上即触发重训或规则调整。

在技术迭代上，后续可以逐步引入更丰富的数据源（如行为日志、设备指纹、外部征信），在保持现有结构的基础上拓展特征体系；对于时间序列较为完整的客户，可以尝试LSTM或基于Transformer的时序模型捕捉还款节奏变化；在模型框架上，探索Stacking或成本敏感集成，将CatBoost的高Precision与LightGBM/XGBoost的高Recall进行策略层融合。整体来看，本次作业验证了以配置化流水线支撑P2P风控落地的可行性，为后续在更大规模场景中的推广打下了基础。
