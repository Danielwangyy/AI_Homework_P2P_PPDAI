# 以贷款合同LC为研究对象，预测逾期的模型技术选型分析

## **1. 项目背景与目标**

本项目面向P2P业务的贷款风险控制环节，目标是建立一套**合同级别的违约预测模型**，用于提前识别未来可能发生逾期的合同，为后续风控策略提供依据。

预测标签采用二分类方式：

* **1（正样本）**：逾期，合同生命周期内出现过的逾期次数大于1，代表坏样本
* **0（负样本）**：未逾期，合同生命周期内出现过逾期次数为0，代表好样本

模型先输出逾期概率，再依据配置的阈值换算成逾期与否，后续可按需调整阈值。

---

## **2. 数据来源与特征处理**

数据来源于三类基础表lC、LP、LCIS，包含合同信息、客户基础信息与还款/行为信息。数据预处理过程包括如下环节：

### **2.1 数据清洗与处理**

| **操作步骤** | **内容与处理方式**                 |
| ------------------ | ---------------------------------------- |
| 异常值处理         | 对金额、期限等指标做区间截断或 Winsorize |
| 缺失值处理         | 分类变量设为 Unknown，数值采用中位数     |
| 重复数据           | 以合同 ID 为单位去重                     |
| 数据泄露过滤       | 删除预测窗口之后可反映未来信息的特征     |

### **2.2 样本划分方式**

当前配置在 `configs/data_processing.yaml` 中启用了**分层随机抽样**，比例仍为 **70% / 15% / 15%**。`prepare_data` 流水线会以标签列为基准执行两段式分层切分，并固定 `random_state=42`，确保每次运行均可复现；当时间窗口设置（`train_end_date` / `val_end_date`）无法满足取样条件时自动退回随机策略，因此不会出现集合为空的情况。

### **2.3 特征工程**

流水线在 `features/engineering.py` 中构建统一的合同级特征集合，并结合标准化、缺失填补与特征选择，核心结构如下：

| **特征类型** | **示例**                                                                                               | **说明**                                   |
| ------------------ | ------------------------------------------------------------------------------------------------------------ | ------------------------------------------------ |
| 合同静态与额度特征 | `loan_amount`、`loan_term`、`interest_rate`、`rating_numeric`、`loan_type_*`                       | 描述合同条款和初始评级，奠定额度、成本与风险敞口 |
| 客户画像与认证信息 | `first_loan_flag`、`user_age`、`phone_verified`、`credit_verified`                                   | 反映客户基本信用画像与认证完整度                 |
| 历史行为与偿付能力 | `history_repay_ratio`、`history_overdue_terms`、`outstanding_principal`、`history_total_amount`      | 捕捉历史偿付表现与现有负债水平                   |
| 派生交互与比例特征 | `loan_term_history_overdue_rate`、`loan_amount_ratio_to_history_avg`、`loan_amount_rating_interaction` | 强化额度/期限与历史逾期的交互关系，凸显趋势变化  |

- **编码与缩放**：数值列统一使用 `StandardScaler`，类别字段执行 One-Hot；缺失值在前序清洗阶段已处理（分类统一为 Unknown，数值以中位数/零填补），因此训练阶段直接复用。
- **特征选择**：启用 `feature_selection.strategy=vote`，综合相关性、卡方检验与树模型重要性，默认保留最高 120 个候选字段，以降低冗余。
- **特征消融**：基线版本通过 `feature_drops` 移除 `loan_date_year` 原始列及其 One-Hot 展开项，减少高度相关的时间标签造成的漂移风险；其他消融实验可按需扩展。

---

## **3. 模型方案与选型依据**

为保证结果可信且具有横向比较价值，本项目构建并对比以下五类模型：

| **模型**        | **类别**   | **优势**                 | **风控适用性**                 |
| --------------------- | ---------------- | ------------------------------ | ------------------------------------ |
| Logistic Regression   | 线性基线模型     | 可解释性强、便于做评分卡       | 监管沟通与策略基线                   |
| Random Forest（预研） | Bagging 集成模型 | 抗噪能力好、易于并行           | 实验阶段保留作对照，当前流水线未启用 |
| LightGBM              | GBDT 提升模型    | 训练效率高、核外计算友好       | 工业界常用，适合大规模部署           |
| XGBoost               | GBDT 提升模型    | 成熟稳定、调参经验丰富         | 作为性能与稳定性的行业基准           |
| CatBoost              | GBDT 提升模型    | 类别特征处理优秀、默认参数稳健 | 推理阶段表现最佳、上线候选           |

选择多模型主要基于：

1. **成本敏感的绩效目标**：阈值调优将 FN:FP 权重设置为 2:1，需要模型在召回率与精确率之间取得平衡。
2. **可解释性要求**：逻辑回归与树模型的特征重要性/SHAP 输出共同满足业务复核需求。
3. **结构化金融数据适配性**：LightGBM、XGBoost、CatBoost 处理高维稀疏特征能力强，能利用交互与比例特征捕捉风险差异。

---

## **4. 模型训练与调参过程**

### **4.1 Logistic Regression 调参摘要**

| **参数** | **调参范围** | **最终值** |
| -------------- | ------------------ | ---------------- |
| C              | 0.1, 1, 10, 20     | 0.1              |
| solver         | lbfgs              | lbfgs            |
| class_weight   | balanced           | balanced         |
| max_iter       | 500                | 500              |

原因：5 折交叉验证的 F1 均值约 0.616（std≈0.002），较强的 L2 正则有助于抑制多重共线特征；`class_weight='balanced'` 与成本敏感阈值共同提升了少数类召回。

---

### **4.2 Random Forest 调研摘要**

> 当前版本的自动流水线未启用随机森林，该模型仅在离线 Notebook 中作为对照实验存在。以下配置供后续人工实验时参考：

| **参数** | **建议范围** | **备注**                 |
| -------------- | ------------------ | ------------------------------ |
| n_estimators   | 200 ~ 400          | 需配合早停或外部验证以控制时长 |
| max_depth      | 5 ~ 9              | 较浅的树可减少过拟合           |
| max_features   | sqrt / log2        | 默认设置在高维稀疏特征上更稳   |

---

### **4.3 LightGBM 调参摘要**

| **参数**    | **搜索范围** | **最终值** |
| ----------------- | ------------------ | ---------------- |
| num_leaves        | 31, 63, 127        | 127              |
| max_depth         | -1, 8              | 8                |
| min_child_samples | 5, 10, 20, 40      | 40               |
| min_split_gain    | 0.0, 0.1           | 0.1              |
| scale_pos_weight  | 自动按成本比计算   | 2.66             |

基础参数固定 `n_estimators=40`、`learning_rate=0.05`、`subsample=0.8`、`colsample_bytree=0.8`。最终 5 折 F1 ≈0.626，验证集在阈值 0.536 下实现 Recall 0.815、Precision 0.508。

---

### **4.4 XGBoost 调参摘要**

| **参数**   | **搜索范围** | **最终值** |
| ---------------- | ------------------ | ---------------- |
| max_depth        | 3, 5               | 5                |
| learning_rate    | 0.03, 0.1          | 0.03             |
| min_child_weight | 1, 5               | 5                |
| gamma            | 0.0, 0.1           | 0.1              |
| subsample        | 0.6, 0.8           | 0.6              |
| scale_pos_weight | 自动按成本比计算   | 2.66             |

固定参数包括 `n_estimators=300`、`colsample_bytree=0.8`、`eval_metric='logloss'`。最终验证 F1 ≈0.627，召回率 0.827，在高阈值下依旧保持较强捕获能力。

---

### **4.5 CatBoost 调参摘要**

| **参数** | **搜索范围** | **最终值** |
| -------------- | ------------------ | ---------------- |
| depth          | 5, 7               | 7                |
| l2_leaf_reg    | 3, 7               | 3                |
| class_weights  | 自动按成本比计算   | [1.0, 4.0]       |
| iterations     | 固定 400           | 400              |
| learning_rate  | 固定 0.05          | 0.05             |

结果：5 折 F1 均值约 0.631，验证集在阈值 0.6845 下 Precision 0.534、Recall 0.743，兼顾稳定性与类别处理能力，是当前上线首选。

---

### **4.6 阈值调优策略**

模型训练完成后，所有候选模型都会经历一次**阈值搜索**，以确定概率转标签的最佳分界线。具体流程如下：

1. 先用 `_predict_with_proba` 获取验证集的逾期概率，默认阈值 0.5 仅用于占位；
2. `_tune_threshold` 根据 `configs/model_training.yaml` 中的 `threshold_tuning` 设置（当前策略为 `cost`，`fn_cost=2`、`fp_cost=1`，201 个等距网格）枚举阈值；
3. 对每个候选阈值计算 `objective_score = -(fn_cost * FN + fp_cost * FP) / N`，得分越高代表综合成本越低；
4. 选择得分最高的阈值作为 `best_threshold`，并存入 `outputs/artifacts/summary_{model}.json`，同时完整搜索轨迹写入 `outputs/artifacts/{model}_threshold_search.csv`，便于复盘。

基于 2025-11-16 的训练结果，不同模型的最优阈值如下：

| **模型**      | **最优阈值** | **验证集 FN** | **验证集 FP** | **objective_score** | **搜索记录**                                             |
| ------------------- | ------------------ | ------------------- | ------------------- | ------------------------- | -------------------------------------------------------------- |
| Logistic Regression | 0.4100             | 1068                | 3758                | -0.5121209488             | `outputs/artifacts/logistic_regression_threshold_search.csv` |
| LightGBM            | 0.5360             | 913                 | 3905                | -0.4979581197             | `outputs/artifacts/lightgbm_threshold_search.csv`            |
| XGBoost             | 0.5450             | 854                 | 4006                | -0.4964810149             | `outputs/artifacts/xgboost_threshold_search.csv`             |
| CatBoost            | 0.6845             | 1268                | 3202                | -0.4985663394             | `outputs/artifacts/catboost_threshold_search.csv`            |

对应的验证集 expected_cost 均落在 **5.7k ±0.1k** 的区间；相较于 FN:FP=5:1 时的 6.5k 左右，新的权重更强调减少误拒好客户，Precision 提升至 0.50~0.53，但需要关注 Recall 从 0.99+ 回落到 0.74~0.83。

这些阈值会被回写到各自的预测与评估环节中，用于生成最终的混淆矩阵、指标表与测试集预测结果。

> 小贴士：默认 `grid_size=201` 会在 0.05~0.95 区间生成等距 201 个候选阈值，既包含默认值 0.5，又保证步长约 0.0045，在精度与计算开销之间取得平衡。可在 `configs/model_training.yaml` 中按需调整。

额外说明：流水线在评估指标时，会同时计算**综合成本** `expected_cost = fp_cost × FP + fn_cost × FN`。其中，FP 表示误杀好客户（拒绝本应通过的合同）的数量，FN 表示漏掉坏客户（释放潜在坏账）的数量。当前配置将 `fn_cost` 设为 2、`fp_cost` 设为 1，代表“漏判坏客户”的损失仍高于误拒，但较以往更强调提升 Precision。阈值搜索正是依据这一成本函数选择最佳阈值；各模型训练完成后，也会在 `model_metrics.*` 中记录同样的 expected_cost，便于横向比较谁的综合成本更低，从而辅助模型选型与策略制定。

---

## **5. 模型评估与效果对比**

评估指标包含 Accuracy、Recall、Precision、F1-score 与 ROC-AUC，重点关注 Recall 指标（尽可能捕捉高风险合同）。

| **模型**      | **Accuracy** | **Precision** | **Recall** | **F1**    | **ROC-AUC** | **综合表现**                                            |
| ------------------- | ------------------ | ------------------- | ---------------- | --------------- | ----------------- | ------------------------------------------------------------- |
| Logistic Regression | 0.579              | 0.506               | 0.786            | 0.615           | 0.669             | 线性基线，便于策略对照（expected_cost≈5.91k）                |
| LightGBM            | 0.580              | 0.506               | **0.816**  | **0.625** | 0.682             | 召回率最高，适合偏保守审核（expected_cost≈5.74k）            |
| XGBoost             | 0.571              | 0.500               | **0.830**  | 0.624           | **0.685**   | 排序能力强，召回领先但 Precision 略低（expected_cost≈5.77k） |
| CatBoost            | **0.610**    | **0.532**     | 0.747            | 0.621           | **0.686**   | Precision/AUC 最优，综合成本最低之一（expected_cost≈5.74k）  |

> 指标取自 `model_metrics.csv` 测试集（运行编号 `model_training_20251116_162130`），所有模型均采用成本策略阈值。

---

## **6. 关键特征分析**

特征重要性排名中，行为与趋势特征优于静态特征，具有一定业务解释性：

| **排名** | **特征**                             | **风险含义（结合 SHAP 与重要性）**                          |
| -------------- | ------------------------------------------ | ----------------------------------------------------------------- |
| 1              | `loan_term`                              | 期限越长、暴露越久，违约概率随之上升                              |
| 2              | `history_repay_ratio`                    | 历史还款率低说明偿付习惯差，模型对其权重最高                      |
| 3              | `loan_term_history_overdue_rate`         | 将期限与历史逾期率结合，识别“长周期+高逾期”的高危组合           |
| 4              | `outstanding_to_history_amount_ratio`    | 当前待还本金占历史借款的比例越高，现金流压力越大                  |
| 5              | `loan_amount` / `loan_amount_per_term` | 更大额度与单期支付负担往往伴随更高风险，需要配合评级/历史指标判断 |

树模型的 SHAP 分析同时强调 `rating_numeric`、`loan_amount_ratio_to_history_avg` 等交互类指标，说明“额度变化+历史表现”是驱动风险判断的主线；认证类字段（如 `credit_verified`、`phone_verified`）仍提供次要但稳定的区分能力。

---

## **7. 结果分析与未来提升方向**

### **7.1 当前阶段结论**

- CatBoost 在 Precision 与 AUC 上领先，expected_cost≈5.74k，适合作为主力上线模型；
- LightGBM / XGBoost 提供更高的召回率，适合作为二线模型或策略兜底，特别是在需要扩大拦截面时；
- Logistic Regression 作为可解释基线，验证了关键特征方向与树模型一致，可协助业务复核；
- 行为与额度交互特征的贡献显著高于单一静态信息，特征选择/消融结果印证了“历史行为 + 额度变化”是驱动信号核心。

### **7.2 未来可提升方向**

1. 继续评估不同成本权重（如 FN:FP=3:1 或分层成本），量化 Precision/Recall 的业务影响；
2. 引入行为日志时间序列建模（LSTM、Transformer）捕捉更细颗粒度的还款节奏；
3. 探索多模型 Stacking/成本敏感集成，平衡 CatBoost 的 Precision 与 GBDT 的 Recall；
4. 构建设备、账户、IP 关联图并引入图模型/GNN，补充关系网络信息；
5. 引入外部信用数据或行业知识特征，进一步提升排序能力与可解释性。

---

## **8. 总结**

本次违约预测模型训练过程遵循**数据清洗 → 特征构建 → 分层切分 → 多模型训练 → 成本敏感调参 → 指标评估 → 可解释分析**的完整工程流程。综合验证/测试集结果，在 **FN:FP = 2:1** 的策略下，CatBoost 凭借更高的 Precision 与 AUC 成为首选上线模型，LightGBM/XGBoost 则在召回方面提供补充。后续可结合成本试算与业务分层策略，将模型推理结果纳入贷后监控与差异化干预，实现自动化风控与人工审核的协同。
